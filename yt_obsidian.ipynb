{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From YouTube to Obsidian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to take a list of youtube links and convert them to markdown notes for Obsidian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import google.generativeai as genai\n",
    "import yaml\n",
    "from google.ai.generativelanguage_v1beta.types import content\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Google API key\n",
    "with open(\"config/credentials.yml\", \"r\") as f:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = yaml.safe_load(f)[\"GEMINI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define system prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_instruction = \"\"\"\n",
    "You will be given a transcript of a youtube video. \n",
    "Your task is make it natural, like a blog post. \n",
    "Add capitalizations, commas, stops or paragraph break when necessary. \n",
    "Only re-write the transcript, don't add anything else like \"Yes, I can do that\" or something like that.\n",
    "And put a timestamp at the beginning of each paragraph so I can easily locate the paragraph in the video later.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key takeaways and tags\n",
    "available_tags = [\n",
    "    \"on/ai\",\n",
    "    \"on/data-science\",\n",
    "    \"on/programming\",\n",
    "    \"on/software-engineering\",\n",
    "    \"on/math\",\n",
    "    \"on/learning\",\n",
    "    \"on/knowledge\",\n",
    "    \"on/productivity\",\n",
    "    \"on/motivation\",\n",
    "    \"on/goals\",\n",
    "    \"on/health\",\n",
    "    \"on/biohacking\",\n",
    "    \"on/reviews\",\n",
    "    \"on/relationships\",\n",
    "    \"on/philosophy\",\n",
    "    \"on/psychology\",\n",
    "    \"on/communication\",\n",
    "    \"on/creativity\",\n",
    "    \"on/leadership\",\n",
    "    \"on/management\",\n",
    "    \"on/design\",\n",
    "    \"on/history\",\n",
    "    \"on/future\",\n",
    "    \"on/pop-culture\",\n",
    "    \"on/politics\",\n",
    "    \"on/self-improvement\",\n",
    "]\n",
    "\n",
    "available_tags_str = \"\\n\".join(available_tags)\n",
    "\n",
    "summary_instruction = f\"\"\"\n",
    "You will be given a transcript of a youtube video along with the metadata. \n",
    "Your task is to write a TL;DR summary of the video (tweet length), the key takeaways, and the tags.\n",
    "The summary should be short and to the point.\n",
    "The key takeaways should be a list of bullet points.\n",
    "The tags should be a list of tags (from one to three) from the following list: \n",
    "{available_tags_str}\n",
    "\n",
    "You MUST use the \"on/\" prefix for the tags. \n",
    "For example, if the video is about AI, you should use \"on/ai\" as the tag.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models and sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "transcript_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=transcript_instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_schema\": content.Schema(\n",
    "        type=content.Type.OBJECT,\n",
    "        enum=[],\n",
    "        required=[\"summary\", \"key_takeaways\", \"tags\"],\n",
    "        properties={\n",
    "            \"summary\": content.Schema(\n",
    "                type=content.Type.STRING,\n",
    "            ),\n",
    "            \"key_takeaways\": content.Schema(\n",
    "                type=content.Type.STRING,\n",
    "            ),\n",
    "            \"tags\": content.Schema(\n",
    "                type=content.Type.ARRAY,\n",
    "                items=content.Schema(\n",
    "                    type=content.Type.STRING,\n",
    "                ),\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "\n",
    "summary_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=summary_instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load videos from videos.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input/test.txt\", \"r\") as f:\n",
    "    video_links = f.readlines()\n",
    "\n",
    "video_links = [link.strip() for link in video_links]\n",
    "print(video_links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a single video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a dictionary with video metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_time(seconds):\n",
    "    \"\"\"Convert seconds to MM:SS format.\"\"\"\n",
    "    return time.strftime(\"%M:%S\", time.gmtime(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\"quiet\": True, \"noprogress\": True}\n",
    "\n",
    "print(f\"Processing video: {video_links[0]}\")\n",
    "print(\"\\tExtracting metadata...\")\n",
    "video_url = video_links[0]\n",
    "with YoutubeDL(opts) as yt:\n",
    "    info = yt.extract_info(video_url, download=False)\n",
    "    video_id = info.get(\"id\")\n",
    "    video_data = {\n",
    "        \"id\": video_id,\n",
    "        \"title\": info.get(\"title\", \"\"),\n",
    "        \"author\": info.get(\"channel\", \"\"),\n",
    "        \"link\": video_url,\n",
    "        \"likes\": info.get(\"like_count\", 0),\n",
    "        \"views\": info.get(\"view_count\", 1),\n",
    "        \"like_rate\": round(100.0 * info.get(\"like_count\") / info.get(\"view_count\"), 2),\n",
    "        \"description\": info.get(\"description\", \"\"),\n",
    "        \"duration\": info.get(\"duration\", 0) / 60,\n",
    "        \"published\": datetime.datetime.strptime(\n",
    "            info.get(\"upload_date\"), \"%Y%m%d\"\n",
    "        ).strftime(\"%Y-%m-%d\"),\n",
    "        \"created\": datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"thumbnail\": info.get(\"thumbnail\", \"\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract the transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tExtracting transcript...\")\n",
    "MAX_MINUTES_FOR_TRANSCRIPT = 15\n",
    "try:\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    transcript_text = \"\\n\".join(\n",
    "        [f\"{fmt_time(entry['start'])} {entry['text']}\" for entry in transcript]\n",
    "    )\n",
    "    video_data[\"transcript\"] = transcript_text\n",
    "except Exception as e:\n",
    "    print(f\"Error getting transcript: {e}\")\n",
    "    video_data[\"transcript\"] = None\n",
    "else:\n",
    "    if video_data[\"duration\"] < MAX_MINUTES_FOR_TRANSCRIPT:\n",
    "        print(\"\\tProcessing transcript...\")\n",
    "        chat_session = transcript_model.start_chat(history=[])\n",
    "        new_transcript_text = chat_session.send_message(transcript_text).text\n",
    "        video_data[\"new_transcript\"] = new_transcript_text\n",
    "    else:\n",
    "        video_data[\"new_transcript\"] = transcript_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate summary and tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tGenerating summary and tags...\")\n",
    "try:\n",
    "    video_data_text = (\n",
    "        \"Title: \" + video_data[\"title\"] + \"\\n\"\n",
    "        \"Author: \" + video_data[\"author\"] + \"\\n\"\n",
    "        \"Transcript:\\n\" + video_data[\"new_transcript\"] + \"\\n\"\n",
    "    )\n",
    "    chat_session = summary_model.start_chat(history=[])\n",
    "    response = chat_session.send_message(video_data_text)\n",
    "    video_data.update(json.loads(response.candidates[0].content.parts[0].text))\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary: {e}\")\n",
    "    video_data[\"summary\"] = video_data[\"description\"]\n",
    "    video_data[\"key_takeaways\"] = \"\"\n",
    "    video_data[\"tags\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dump to markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tDumping to markdown...\")\n",
    "note_title = video_data[\"title\"].replace(\".\", \"\").replace(\"/\", \"\") + \".md\"\n",
    "tags_str = \"\"\n",
    "for tag in video_data[\"tags\"]:\n",
    "    tags_str += f'  - \"{tag}\"\\n'\n",
    "\n",
    "note = f\"\"\"\n",
    "---\n",
    "title: \"{video_data['title']}\"\n",
    "source: \"{video_data['link']}\"\n",
    "author:\n",
    "  - \"[[{video_data['author']}]]\"\n",
    "published: {video_data['published']}\n",
    "created: {video_data['created']}\n",
    "description: \"{video_data['summary']}\"\n",
    "tags:\n",
    "{tags_str}\n",
    "---\n",
    "[![Thumbnail]({video_data['thumbnail']})]({video_data['link']})\n",
    "\n",
    "{video_data['summary']}\n",
    "\n",
    "## Key takeaways\n",
    "{video_data['key_takeaways']}\n",
    "\n",
    "## Transcript\n",
    "{video_data['new_transcript']}\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(\"output/\" + note_title, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(note)\n",
    "    print(f\"\\tNote saved to notes/{note_title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function and loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data(video_link):\n",
    "    opts = {\"quiet\": True, \"noprogress\": True}\n",
    "    print(\"\\tExtracting metadata...\")\n",
    "    with YoutubeDL(opts) as yt:\n",
    "        info = yt.extract_info(video_link, download=False)\n",
    "        video_id = info.get(\"id\")\n",
    "        video_data = {\n",
    "            \"id\": video_id,\n",
    "            \"title\": info.get(\"title\", \"\"),\n",
    "            \"author\": info.get(\"channel\", \"\"),\n",
    "            \"link\": video_link,\n",
    "            \"likes\": info.get(\"like_count\", 0),\n",
    "            \"views\": info.get(\"view_count\", 1),\n",
    "            \"like_rate\": round(\n",
    "                100.0 * info.get(\"like_count\") / info.get(\"view_count\"), 2\n",
    "            ),\n",
    "            \"description\": info.get(\"description\", \"\"),\n",
    "            \"duration\": info.get(\"duration\", 0) / 60,\n",
    "            \"published\": datetime.datetime.strptime(\n",
    "                info.get(\"upload_date\"), \"%Y%m%d\"\n",
    "            ).strftime(\"%Y-%m-%d\"),\n",
    "            \"created\": datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            \"thumbnail\": info.get(\"thumbnail\", \"\"),\n",
    "        }\n",
    "\n",
    "    return video_data\n",
    "\n",
    "\n",
    "def enrich_video_data(video_data):\n",
    "    print(\"\\tExtracting transcript...\")\n",
    "    MAX_MINUTES_FOR_TRANSCRIPT = 15\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_data[\"id\"])\n",
    "        transcript_text = \"\\n\".join(\n",
    "            [f\"{fmt_time(entry['start'])} {entry['text']}\" for entry in transcript]\n",
    "        )\n",
    "        video_data[\"transcript\"] = transcript_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting transcript: {e}\")\n",
    "        video_data[\"transcript\"] = None\n",
    "    else:\n",
    "        if video_data[\"duration\"] < MAX_MINUTES_FOR_TRANSCRIPT:\n",
    "            print(\"\\tProcessing transcript...\")\n",
    "            chat_session = transcript_model.start_chat(history=[])\n",
    "            new_transcript_text = chat_session.send_message(transcript_text).text\n",
    "            video_data[\"new_transcript\"] = new_transcript_text\n",
    "        else:\n",
    "            video_data[\"new_transcript\"] = transcript_text\n",
    "\n",
    "    print(\"\\tGenerating summary and tags...\")\n",
    "    try:\n",
    "        video_data_text = (\n",
    "            \"Title: \" + video_data[\"title\"] + \"\\n\"\n",
    "            \"Author: \" + video_data[\"author\"] + \"\\n\"\n",
    "            \"Transcript:\\n\" + video_data[\"new_transcript\"] + \"\\n\"\n",
    "        )\n",
    "        chat_session = summary_model.start_chat(history=[])\n",
    "        response = chat_session.send_message(video_data_text)\n",
    "        video_data.update(json.loads(response.candidates[0].content.parts[0].text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        video_data[\"summary\"] = video_data[\"description\"]\n",
    "        video_data[\"key_takeaways\"] = \"\"\n",
    "        video_data[\"tags\"] = []\n",
    "\n",
    "    return video_data\n",
    "\n",
    "\n",
    "def save_note(video_data):\n",
    "    print(\"\\tDumping to markdown...\")\n",
    "    note_title = video_data[\"title\"].replace(\".\", \"\").replace(\"/\", \"\") + \".md\"\n",
    "    tags_str = \"\"\n",
    "    for tag in video_data[\"tags\"]:\n",
    "        tags_str += f'  - \"{tag}\"\\n'\n",
    "\n",
    "    note = (\n",
    "        \"---\\n\"\n",
    "        f'title: \"{video_data[\"title\"]}\"\\n'\n",
    "        f'source: \"{video_data[\"link\"]}\"\\n'\n",
    "        \"author:\\n\"\n",
    "        f'- \"[[{video_data[\"author\"]}]]\"\\n'\n",
    "        f'published: {video_data[\"published\"]}\\n'\n",
    "        f'created: {video_data[\"created\"]}\\n'\n",
    "        f'description: \"{video_data[\"summary\"]}\"\\n'\n",
    "        f'like_rate: {video_data[\"like_rate\"]}\\n'\n",
    "        \"tags:\\n\"\n",
    "        f\"{tags_str}\\n\"\n",
    "        \"---\\n\\n\"\n",
    "        f'[![Thumbnail]({video_data[\"thumbnail\"]})]({video_data[\"link\"]})\\n\\n'\n",
    "        f'{video_data[\"summary\"]}\\n\\n'\n",
    "        \"## Key takeaways\\n\"\n",
    "        f'{video_data[\"key_takeaways\"]}\\n\\n'\n",
    "        \"## Transcript\\n\"\n",
    "        f'{video_data[\"new_transcript\"]}'\n",
    "    )\n",
    "\n",
    "    with open(\"notes/\" + note_title, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(note)\n",
    "        print(f\"\\tNote saved to notes/{note_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"videos.txt\", \"r\") as f:\n",
    "    video_links = f.readlines()\n",
    "\n",
    "video_links = [link.strip() for link in video_links]\n",
    "print(\"No videos to process: \", len(video_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, video_link in enumerate(video_links, 1):\n",
    "    print(f\"Processing video {i}/{len(video_links)}: {video_link}\")\n",
    "    video_data = get_video_data(video_link)\n",
    "\n",
    "    # Check if already exists\n",
    "    note_title = video_data[\"title\"].replace(\".\", \"\").replace(\"/\", \"\") + \".md\"\n",
    "    if os.path.exists(\"notes/\" + note_title):\n",
    "        print(\"\\tNote already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    video_data = enrich_video_data(video_data)\n",
    "    save_note(video_data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototyping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
