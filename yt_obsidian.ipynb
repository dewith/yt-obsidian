{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From YouTube to Obsidian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to take a list of youtube links and convert them to markdown notes for Obsidian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import UTC, datetime\n",
    "\n",
    "import google.generativeai as genai\n",
    "import yaml\n",
    "from google.ai.generativelanguage_v1beta.types import content\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from yt_dlp import YoutubeDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Google API key\n",
    "with open(\"config/credentials.yml\", \"r\") as f:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = yaml.safe_load(f)[\"GEMINI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define system prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_instruction = \"\"\"\n",
    "You will be given a transcript of a youtube video. \n",
    "Your task is make it natural, like a blog post. \n",
    "Add capitalizations, commas, stops or paragraph break when necessary. \n",
    "Only re-write the transcript, don't add anything else like \"Yes, I can do that\" or something like that.\n",
    "And put a timestamp at the beginning of each paragraph so I can easily locate the paragraph in the video later.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key takeaways and tags\n",
    "available_tags = [\n",
    "    \"on/ai\",\n",
    "    \"on/data-science\",\n",
    "    \"on/programming\",\n",
    "    \"on/software-engineering\",\n",
    "    \"on/math\",\n",
    "    \"on/learning\",\n",
    "    \"on/knowledge\",\n",
    "    \"on/productivity\",\n",
    "    \"on/motivation\",\n",
    "    \"on/goals\",\n",
    "    \"on/health\",\n",
    "    \"on/biohacking\",\n",
    "    \"on/reviews\",\n",
    "    \"on/relationships\",\n",
    "    \"on/philosophy\",\n",
    "    \"on/psychology\",\n",
    "    \"on/communication\",\n",
    "    \"on/creativity\",\n",
    "    \"on/leadership\",\n",
    "    \"on/management\",\n",
    "    \"on/design\",\n",
    "    \"on/history\",\n",
    "    \"on/future\",\n",
    "    \"on/pop-culture\",\n",
    "    \"on/politics\",\n",
    "    \"on/self-improvement\",\n",
    "]\n",
    "\n",
    "available_tags_str = \"\\n\".join(available_tags)\n",
    "\n",
    "summary_instruction = f\"\"\"\n",
    "You will be given a transcript of a youtube video along with the metadata. \n",
    "Your task is to write a TL;DR summary of the video (tweet length), the key takeaways, and the tags.\n",
    "The summary should be short and to the point.\n",
    "The key takeaways should be a list of bullet points.\n",
    "The tags should be a list of tags (from one to three) from the following list: \n",
    "{available_tags_str}\n",
    "\n",
    "You MUST use the \"on/\" prefix for the tags. \n",
    "For example, if the video is about AI, you should use \"on/ai\" as the tag.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models and sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "transcript_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=transcript_instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_schema\": content.Schema(\n",
    "        type=content.Type.OBJECT,\n",
    "        enum=[],\n",
    "        required=[\"summary\", \"key_takeaways\", \"tags\"],\n",
    "        properties={\n",
    "            \"summary\": content.Schema(\n",
    "                type=content.Type.STRING,\n",
    "            ),\n",
    "            \"key_takeaways\": content.Schema(\n",
    "                type=content.Type.STRING,\n",
    "            ),\n",
    "            \"tags\": content.Schema(\n",
    "                type=content.Type.ARRAY,\n",
    "                items=content.Schema(\n",
    "                    type=content.Type.STRING,\n",
    "                ),\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "\n",
    "summary_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=summary_instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load videos from videos.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://youtube.com/watch?v=N4YjXJVzoZY', 'https://youtube.com/watch?v=AOYUEqlWOGU', 'https://youtube.com/watch?v=3kKB6wYqP7Y', 'https://youtube.com/watch?v=vTmixSgeOI0', 'https://youtube.com/watch?v=YSMWN8VpY6A']\n"
     ]
    }
   ],
   "source": [
    "def get_video_links() -> list:\n",
    "    \"\"\"Get video links from a txt file.\"\"\"\n",
    "    with open(\"input/play.txt\", \"r\") as f:\n",
    "        video_links = f.readlines()\n",
    "\n",
    "    # Extract URLs from each line\n",
    "    pat = re.compile(r\"(https?://[^\\s]+)\")\n",
    "    video_links = [pat.findall(line)[0] for line in video_links]\n",
    "    # Remove duplicates while preserving order\n",
    "    video_links = list(dict.fromkeys(video_links))\n",
    "    return video_links\n",
    "\n",
    "\n",
    "video_links = get_video_links()\n",
    "print(video_links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_time(seconds: int) -> str:\n",
    "    \"\"\"Convert seconds to MM:SS format.\"\"\"\n",
    "    return time.strftime(\"%M:%S\", time.gmtime(seconds))\n",
    "\n",
    "\n",
    "def get_note_title(video_title: str) -> str:\n",
    "    \"\"\"Get a valid note title from a video title.\"\"\"\n",
    "    # Remove special characters including dots and slashes, and emojis\n",
    "    note_title = re.sub(r\"[^\\w\\s']\", \"\", video_title).capitalize()\n",
    "    return note_title + \".md\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a single video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a dictionary with video metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: https://youtube.com/watch?v=N4YjXJVzoZY\n",
      "\tExtracting metadata...\n",
      "{\n",
      "  \"id\": \"N4YjXJVzoZY\",\n",
      "  \"title\": \"Mini Essays: The Ultimate Learning Tool\",\n",
      "  \"author\": \"Odysseas\",\n",
      "  \"link\": \"https://youtube.com/watch?v=N4YjXJVzoZY\",\n",
      "  \"likes\": 36067,\n",
      "  \"views\": 457299,\n",
      "  \"like_rate\": 7.89,\n",
      "  \"description\": \"About 8 months ago, I started using mini-essays as the core of my note-taking. I'll never turn back.\\n\\nI like to take my time with books, analyse their points and take time to write about them. It's high effort, sure, but the knowledge you get in return is priceless.\\n\\nMini-essays have been my best friend in this journey. They help me understand hard books, remember big ideas and form interesting connections, all with 30 minutes of time here and there.\\n\\nAnd that's only half the value. By writing mini-essays, I kill two birds with one stone. I'm on a journey to become a better writer, and these notes are a perfect way to practice writing and find my voice. Not bad, right?\\n\\nIn this video, I talk about how and why you might add mini-essays to your workflow to take learning to the next level.\\n\\nNewsletter:\\nhttps://odysseas.ck.page/509a9315a4\\n\\nRobert Henderson Article:\\nhttps://www.robkhenderson.com/p/31-lessons-i-learned-from-thomas?publication_id=800237&post_id=134731673&isFreemail=true\\n\\nJoin me on X:\\nhttps://twitter.com/odysseas_px\\n\\nTIMESTAMPS\\n00:00-00:40 What Are They?\\n00:40-1:45 How I Use Them + Example\\n1:45-2:40 High Effort, High Reward\\n2:40-6:00 How Mini-Essays Help You Learn\\n6:00-8:00 How to Become a Great Writer\\n8:00-9:06 Boost Writing Output\\n9:06-10:27 Make Writing Addictive\\n10:27-12:36 Build a Bank of Ideas\\n12:36-15:38 How and Where to Start\\n15:38-16:04 Last Note\",\n",
      "  \"duration\": 16.1,\n",
      "  \"published\": \"2024-03-03\",\n",
      "  \"created\": \"2024-12-08\",\n",
      "  \"thumbnail\": \"https://i.ytimg.com/vi/N4YjXJVzoZY/maxresdefault.jpg\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "opts = {\"quiet\": True, \"noprogress\": True}\n",
    "\n",
    "print(f\"Processing video: {video_links[0]}\")\n",
    "print(\"\\tExtracting metadata...\")\n",
    "video_link = video_links[0]\n",
    "with YoutubeDL(opts) as yt:\n",
    "    info = yt.extract_info(video_link, download=False)\n",
    "    views = info.get(\"view_count\", 1)\n",
    "    likes = info.get(\"like_count\", 0)\n",
    "    like_rate = round(100.0 * likes / views, 2)\n",
    "    published = datetime.strptime(info.get(\"upload_date\", \"\"), \"%Y%m%d\")\n",
    "    video_data = {\n",
    "        \"id\": info.get(\"id\"),\n",
    "        \"title\": info.get(\"title\", \"\"),\n",
    "        \"author\": info.get(\"channel\", \"\"),\n",
    "        \"link\": video_link,\n",
    "        \"likes\": likes,\n",
    "        \"views\": views,\n",
    "        \"like_rate\": like_rate,\n",
    "        \"description\": info.get(\"description\", \"\"),\n",
    "        \"duration\": round(info.get(\"duration\", 0) / 60, 1),\n",
    "        \"published\": published.strftime(\"%Y-%m-%d\"),\n",
    "        \"created\": datetime.now(tz=UTC).strftime(\"%Y-%m-%d\"),\n",
    "        \"thumbnail\": info.get(\"thumbnail\", \"\"),\n",
    "    }\n",
    "\n",
    "print(json.dumps(video_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract the transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExtracting transcript...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tExtracting transcript...\")\n",
    "MAX_MINUTES_FOR_TRANSCRIPT = 15\n",
    "try:\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_data[\"id\"])\n",
    "    transcript_text = \"\\n\".join(\n",
    "        [f\"{fmt_time(entry['start'])} {entry['text']}\" for entry in transcript]\n",
    "    )\n",
    "    video_data[\"transcript\"] = transcript_text\n",
    "except Exception as e:\n",
    "    print(f\"Error getting transcript: {e}\")\n",
    "    video_data[\"transcript\"] = None\n",
    "else:\n",
    "    if video_data[\"duration\"] < MAX_MINUTES_FOR_TRANSCRIPT:\n",
    "        print(\"\\tProcessing transcript...\")\n",
    "        chat_session = transcript_model.start_chat(history=[])\n",
    "        new_transcript_text = chat_session.send_message(transcript_text).text\n",
    "        video_data[\"new_transcript\"] = new_transcript_text\n",
    "    else:\n",
    "        video_data[\"new_transcript\"] = transcript_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate summary and tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerating summary and tags...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tGenerating summary and tags...\")\n",
    "try:\n",
    "    video_data_text = (\n",
    "        \"Title: \" + video_data[\"title\"] + \"\\n\"\n",
    "        \"Author: \" + video_data[\"author\"] + \"\\n\"\n",
    "        \"Transcript:\\n\" + video_data[\"new_transcript\"] + \"\\n\"\n",
    "    )\n",
    "    chat_session = summary_model.start_chat(history=[])\n",
    "    response = chat_session.send_message(video_data_text)\n",
    "    video_data.update(json.loads(response.candidates[0].content.parts[0].text))\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary: {e}\")\n",
    "    video_data[\"summary\"] = video_data[\"description\"]\n",
    "    video_data[\"key_takeaways\"] = \"\"\n",
    "    video_data[\"tags\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dump to markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDumping to markdown...\n",
      "\tNote saved to notes/Mini essays the ultimate learning tool.md\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tDumping to markdown...\")\n",
    "note_title = get_note_title(video_data[\"title\"])\n",
    "note_path = os.path.join(\"output\", note_title)\n",
    "tags_str = \"\"\n",
    "for tag in video_data[\"tags\"]:\n",
    "    tags_str += f'  - \"{tag}\"\\n'\n",
    "\n",
    "note = (\n",
    "    \"---\\n\"\n",
    "    f'title: \"{video_data[\"title\"]}\"\\n'\n",
    "    f'source: \"{video_data[\"link\"]}\"\\n'\n",
    "    \"author:\\n\"\n",
    "    f'- \"[[{video_data[\"author\"]}]]\"\\n'\n",
    "    f'published: {video_data[\"published\"]}\\n'\n",
    "    f'created: {video_data[\"created\"]}\\n'\n",
    "    f'description: \"{video_data[\"summary\"]}\"\\n'\n",
    "    f'like_rate: {video_data[\"like_rate\"]}\\n'\n",
    "    \"tags:\\n\"\n",
    "    f\"{tags_str}\\n\"\n",
    "    \"---\\n\\n\"\n",
    "    f'[![Thumbnail]({video_data[\"thumbnail\"]})]({video_data[\"link\"]})\\n\\n'\n",
    "    f'{video_data[\"summary\"]}\\n\\n'\n",
    "    \"## Key takeaways\\n\"\n",
    "    f'{video_data[\"key_takeaways\"]}\\n\\n'\n",
    "    \"## Transcript\\n\"\n",
    "    f'{video_data[\"new_transcript\"]}'\n",
    ")\n",
    "\n",
    "with open(\"output/\" + note_title, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(note)\n",
    "    print(f\"\\tNote saved to notes/{note_title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function and loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data(video_link):\n",
    "    opts = {\"quiet\": True, \"noprogress\": True}\n",
    "    print(\"\\tExtracting metadata...\")\n",
    "    with YoutubeDL(opts) as yt:\n",
    "        info = yt.extract_info(video_link, download=False)\n",
    "        video_id = info.get(\"id\")\n",
    "        video_data = {\n",
    "            \"id\": video_id,\n",
    "            \"title\": info.get(\"title\", \"\"),\n",
    "            \"author\": info.get(\"channel\", \"\"),\n",
    "            \"link\": video_link,\n",
    "            \"likes\": info.get(\"like_count\", 0),\n",
    "            \"views\": info.get(\"view_count\", 1),\n",
    "            \"like_rate\": round(\n",
    "                100.0 * info.get(\"like_count\") / info.get(\"view_count\"), 2\n",
    "            ),\n",
    "            \"description\": info.get(\"description\", \"\"),\n",
    "            \"duration\": info.get(\"duration\", 0) / 60,\n",
    "            \"published\": datetime.datetime.strptime(\n",
    "                info.get(\"upload_date\"), \"%Y%m%d\"\n",
    "            ).strftime(\"%Y-%m-%d\"),\n",
    "            \"created\": datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            \"thumbnail\": info.get(\"thumbnail\", \"\"),\n",
    "        }\n",
    "\n",
    "    return video_data\n",
    "\n",
    "\n",
    "def enrich_video_data(video_data):\n",
    "    print(\"\\tExtracting transcript...\")\n",
    "    MAX_MINUTES_FOR_TRANSCRIPT = 15\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_data[\"id\"])\n",
    "        transcript_text = \"\\n\".join(\n",
    "            [f\"{fmt_time(entry['start'])} {entry['text']}\" for entry in transcript]\n",
    "        )\n",
    "        video_data[\"transcript\"] = transcript_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting transcript: {e}\")\n",
    "        video_data[\"transcript\"] = None\n",
    "    else:\n",
    "        if video_data[\"duration\"] < MAX_MINUTES_FOR_TRANSCRIPT:\n",
    "            print(\"\\tProcessing transcript...\")\n",
    "            chat_session = transcript_model.start_chat(history=[])\n",
    "            new_transcript_text = chat_session.send_message(transcript_text).text\n",
    "            video_data[\"new_transcript\"] = new_transcript_text\n",
    "        else:\n",
    "            video_data[\"new_transcript\"] = transcript_text\n",
    "\n",
    "    print(\"\\tGenerating summary and tags...\")\n",
    "    try:\n",
    "        video_data_text = (\n",
    "            \"Title: \" + video_data[\"title\"] + \"\\n\"\n",
    "            \"Author: \" + video_data[\"author\"] + \"\\n\"\n",
    "            \"Transcript:\\n\" + video_data[\"new_transcript\"] + \"\\n\"\n",
    "        )\n",
    "        chat_session = summary_model.start_chat(history=[])\n",
    "        response = chat_session.send_message(video_data_text)\n",
    "        video_data.update(json.loads(response.candidates[0].content.parts[0].text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        video_data[\"summary\"] = video_data[\"description\"]\n",
    "        video_data[\"key_takeaways\"] = \"\"\n",
    "        video_data[\"tags\"] = []\n",
    "\n",
    "    return video_data\n",
    "\n",
    "\n",
    "def save_note(video_data):\n",
    "    print(\"\\tDumping to markdown...\")\n",
    "    note_title = video_data[\"title\"].replace(\".\", \"\").replace(\"/\", \"\") + \".md\"\n",
    "    tags_str = \"\"\n",
    "    for tag in video_data[\"tags\"]:\n",
    "        tags_str += f'  - \"{tag}\"\\n'\n",
    "\n",
    "    note = (\n",
    "        \"---\\n\"\n",
    "        f'title: \"{video_data[\"title\"]}\"\\n'\n",
    "        f'source: \"{video_data[\"link\"]}\"\\n'\n",
    "        \"author:\\n\"\n",
    "        f'- \"[[{video_data[\"author\"]}]]\"\\n'\n",
    "        f'published: {video_data[\"published\"]}\\n'\n",
    "        f'created: {video_data[\"created\"]}\\n'\n",
    "        f'description: \"{video_data[\"summary\"]}\"\\n'\n",
    "        f'like_rate: {video_data[\"like_rate\"]}\\n'\n",
    "        \"tags:\\n\"\n",
    "        f\"{tags_str}\\n\"\n",
    "        \"---\\n\\n\"\n",
    "        f'[![Thumbnail]({video_data[\"thumbnail\"]})]({video_data[\"link\"]})\\n\\n'\n",
    "        f'{video_data[\"summary\"]}\\n\\n'\n",
    "        \"## Key takeaways\\n\"\n",
    "        f'{video_data[\"key_takeaways\"]}\\n\\n'\n",
    "        \"## Transcript\\n\"\n",
    "        f'{video_data[\"new_transcript\"]}'\n",
    "    )\n",
    "\n",
    "    with open(\"notes/\" + note_title, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(note)\n",
    "        print(f\"\\tNote saved to notes/{note_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"videos.txt\", \"r\") as f:\n",
    "    video_links = f.readlines()\n",
    "\n",
    "video_links = [link.strip() for link in video_links]\n",
    "print(\"No videos to process: \", len(video_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, video_link in enumerate(video_links, 1):\n",
    "    print(f\"Processing video {i}/{len(video_links)}: {video_link}\")\n",
    "    video_data = get_video_data(video_link)\n",
    "\n",
    "    # Check if already exists\n",
    "    note_title = video_data[\"title\"].replace(\".\", \"\").replace(\"/\", \"\") + \".md\"\n",
    "    if os.path.exists(\"notes/\" + note_title):\n",
    "        print(\"\\tNote already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    video_data = enrich_video_data(video_data)\n",
    "    save_note(video_data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototyping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
